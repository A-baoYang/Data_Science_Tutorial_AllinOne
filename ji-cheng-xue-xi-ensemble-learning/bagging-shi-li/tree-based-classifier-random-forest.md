---
description: 集成學習 Bagging 方法的代表算法及進化版：隨機森林
---

# Random Forest

## 概念

* 在 bagging 的樣本隨機抽樣基礎上，再加上特徵隨機選擇

### 為什麼隨機森林能確保比單棵決策樹表現更好？

盡量使隨機森林中的每棵樹都不同

#### random_state

* 利用「隨機挑選特徵進行分支」的隨機性，隨機性越大，成效越好
* 但是資料集中的特徵數量是有限的，要持續增加隨機性，需要其他參數設定

#### bootstrap 有放回的隨機抽樣

* 每次都抽樣不同的訓練集來進行訓練，得到（分枝）不同的決策樹
* 採樣 n 次取後放回，最終得到一個和原始訓練集一樣大、由 n 個樣本組成的抽樣集；如此一來每次的抽樣集都是相同大小、但分佈不同的，使得每棵決策樹訓練起來也不同
* **袋外數據（out-of-bag data，oob）**：有放回的隨機抽樣，當樣本數和樹木數量夠多時，可能有 37% 左右的資料會抽不到；可以變相的將沒抽到過的樣本作為測試集使用。

#### oob_score

* 將 `oob_score` 設為 `True`
* 檢視以袋外數據做為測試集的效果：`model.oob_score_`







##
